{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, auc, roc_curve, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import model_selection\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('KNN9', KNeighborsClassifier(n_neighbors=9)))\n",
    "models.append(('KNN7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('KNN5', KNeighborsClassifier()))\n",
    "models.append(('KNN3', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('KNN1', KNeighborsClassifier(n_neighbors=1)))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "\n",
    "features = []\n",
    "trained_models = []\n",
    "\n",
    "def getColumnsZeroStd():\n",
    "    benign = pd.read_csv(\"./dataset_benign.csv\")\n",
    "    malware = pd.read_csv(\"./dataset_malware.csv\")\n",
    "\n",
    "    drop = ['Name', 'Malware']\n",
    "    \n",
    "    b = benign.drop(['Name', 'Malware'], axis=1)\n",
    "    m = malware.drop(['Name', 'Malware'], axis=1)\n",
    "    for feature in b.columns:\n",
    "        # print(feature)\n",
    "        if b[feature].std() == 0:\n",
    "            drop.append(feature)\n",
    "    for feature in m.columns:\n",
    "        # print(feature)\n",
    "        if m[feature].std() == 0:\n",
    "            if feature not in drop:\n",
    "                drop.append(feature)\n",
    "\n",
    "    print(drop)\n",
    "    print(len(drop))\n",
    "\n",
    "    return drop\n",
    "\n",
    "def buildDataset(resample=\"\", drop=['Name', 'Malware']):\n",
    "    benign = pd.read_csv(\"./dataset_benign.csv\")\n",
    "    malware = pd.read_csv(\"./dataset_malware.csv\")\n",
    "\n",
    "    data = pd.concat([benign, malware], ignore_index=True)\n",
    "\n",
    "    X = data.drop(drop, axis=1)\n",
    "    y = data['Malware']\n",
    "\n",
    "    # print(names)\n",
    "\n",
    "    if (resample == \"-o\"):\n",
    "        print(\"Aplicando oversampling...\")\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "    elif (resample == \"-u\"):\n",
    "        print(\"\\n\\n\\nAplicando undersampling...\")\n",
    "        nearmiss = NearMiss(version=1)\n",
    "        X, y = nearmiss.fit_resample(X, y)\n",
    "\n",
    "    print(\"Número de muestras totales:\", len(X), \"\\n\\n\\n\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def trainTest(X, y):\n",
    "    global features\n",
    "    features = X.columns\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "    sc = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    print(f'Número de características usadas: {X_train.shape[1]} \\n\\n\\n')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def crossValidationScore(X_train, y_train):\n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'accuracy'\n",
    "    print(\"COMPARACIÓNN DE ALGORITMOS MEDIANTE CROSS-VALIDATION\")\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10)\n",
    "        trained_model = model.fit(X_train, y_train)\n",
    "        cv_results = model_selection.cross_val_score(\n",
    "            trained_model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        trained_models.append((name, trained_model))\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "def compareMLAs(X_train, X_test, y_train, y_test):\n",
    "    MLA_columns = []\n",
    "    MLA_compare = pd.DataFrame(columns=MLA_columns)\n",
    "\n",
    "    row_index = 0\n",
    "    for name, model in trained_models:\n",
    "\n",
    "        predicted = model.predict(X_test)\n",
    "\n",
    "        fp, tp, th = roc_curve(y_test, predicted)\n",
    "        MLA_name = name\n",
    "        MLA_compare.loc[row_index, 'MLA used'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'Train Accuracy'] = round(\n",
    "            model.score(X_train, y_train), 4)\n",
    "        MLA_compare.loc[row_index, 'Test Accuracy'] = round(\n",
    "            model.score(X_test, y_test), 4)\n",
    "        MLA_compare.loc[row_index, 'Precision'] = precision_score(\n",
    "            y_test, predicted)\n",
    "        MLA_compare.loc[row_index, 'Recall'] = recall_score(y_test, predicted)\n",
    "        MLA_compare.loc[row_index, 'F1-Score'] = f1_score(\n",
    "            y_test, predicted)\n",
    "        # MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)\n",
    "\n",
    "        row_index += 1\n",
    "\n",
    "    MLA_compare.sort_values(by=['Test Accuracy'],\n",
    "                            ascending=False, inplace=True)\n",
    "    print(MLA_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aplicando undersampling...\n",
      "Número de muestras totales: 8228 \n",
      "\n",
      "\n",
      "\n",
      "Número de características usadas: 76 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resample=\"-u\" #\"-u\" -> aplicar undersampling    \"-o\" -> aplicar oversampling    \"\" -> no aplica ningun resampling\n",
    "\n",
    "X,y = buildDataset(resample)\n",
    "X_train, X_test, y_train, y_test = trainTest(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationScore(X_train, y_train)\n",
    "compareMLAs(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características usadas: 47 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corrMatrix = X.corr()\n",
    "correlated_features = set()\n",
    "for i in range(len(corrMatrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corrMatrix.iloc[i, j]) > 0.8:\n",
    "            colname = corrMatrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "len(correlated_features)\n",
    "X.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "# print(corrMatrix)\n",
    "# f, ax = plt.subplots(figsize =(20, 18))\n",
    "# sns.heatmap(corrMatrix, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1)\n",
    "X_train, X_test, y_train, y_test = trainTest(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationScore(X_train, y_train)\n",
    "compareMLAs(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\OneDrive\\Escritorio\\TFG\\models.ipynb Celda 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m sel\u001b[39m.\u001b[39mfit_transform(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39m# print(X)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=3'>4</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m trainTest(X, y)\n",
      "\u001b[1;32mc:\\Users\\samue\\OneDrive\\Escritorio\\TFG\\models.ipynb Celda 6\u001b[0m in \u001b[0;36mtrainTest\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=92'>93</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrainTest\u001b[39m(X, y):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=93'>94</a>\u001b[0m     \u001b[39mglobal\u001b[39;00m features\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=94'>95</a>\u001b[0m     features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=96'>97</a>\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=97'>98</a>\u001b[0m         X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m101\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/samue/OneDrive/Escritorio/TFG/models.ipynb#ch0000005?line=99'>100</a>\u001b[0m     sc \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit(X_train)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# sel = VarianceThreshold(threshold=(0.1))\n",
    "# X = sel.fit_transform(X)\n",
    "# # print(X)\n",
    "# X_train, X_test, y_train, y_test = trainTest(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationScore(X_train, y_train)\n",
    "compareMLAs(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Malware', 'e_magic', 'e_cblp', 'e_cp', 'e_crlc', 'e_cparhdr', 'e_minalloc', 'e_maxalloc', 'e_ss', 'e_sp', 'e_csum', 'e_ip', 'e_cs', 'e_lfarlc', 'e_ovno', 'PointerToSymbolTable', 'NumberOfSymbols', 'LoaderFlags', 'NumberOfRvaAndSizes', 'SuspiciousNameSection', 'SectionMaxEntropy', 'SectionMaxRawsize', 'SectionMaxVirtualsize', 'SectionMinPhysical', 'SectionMinVirtual', 'SectionMinPointerData', 'SectionMainChar']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "drop = getColumnsZeroStd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aplicando undersampling...\n",
      "Número de muestras totales: 8228 \n",
      "\n",
      "\n",
      "\n",
      "Número de características usadas: 50 \n",
      "\n",
      "\n",
      "\n",
      "Index(['e_oemid', 'e_oeminfo', 'e_lfanew', 'Machine', 'NumberOfSections',\n",
      "       'TimeDateStamp', 'SizeOfOptionalHeader', 'Characteristics', 'Magic',\n",
      "       'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode',\n",
      "       'SizeOfInitializedData', 'SizeOfUninitializedData',\n",
      "       'AddressOfEntryPoint', 'BaseOfCode', 'ImageBase', 'SectionAlignment',\n",
      "       'FileAlignment', 'MajorOperatingSystemVersion',\n",
      "       'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion',\n",
      "       'MajorSubsystemVersion', 'MinorSubsystemVersion', 'SizeOfHeaders',\n",
      "       'CheckSum', 'SizeOfImage', 'Subsystem', 'DllCharacteristics',\n",
      "       'SizeOfStackReserve', 'SizeOfStackCommit', 'SizeOfHeapReserve',\n",
      "       'SizeOfHeapCommit', 'SectionsLength', 'SectionMinEntropy',\n",
      "       'SectionMinRawsize', 'SectionMinVirtualsize', 'SectionMaxPhysical',\n",
      "       'SectionMaxVirtual', 'SectionMaxPointerData', 'SectionMaxChar',\n",
      "       'DirectoryEntryImport', 'DirectoryEntryImportSize',\n",
      "       'DirectoryEntryExport', 'ImageDirectoryEntryExport',\n",
      "       'ImageDirectoryEntryImport', 'ImageDirectoryEntryResource',\n",
      "       'ImageDirectoryEntryException', 'ImageDirectoryEntrySecurity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "resample=\"-u\" #\"-u\" -> aplicar undersampling    \"-o\" -> aplicar oversampling    \"\" -> no aplica ningun resampling\n",
    "\n",
    "X,y = buildDataset(resample, drop)\n",
    "X_train, X_test, y_train, y_test = trainTest(X, y)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características usadas: 28 \n",
      "\n",
      "\n",
      "\n",
      "Index(['e_oemid', 'e_oeminfo', 'e_lfanew', 'Machine', 'NumberOfSections',\n",
      "       'TimeDateStamp', 'Characteristics', 'MajorLinkerVersion', 'SizeOfCode',\n",
      "       'SizeOfInitializedData', 'SizeOfUninitializedData', 'BaseOfCode',\n",
      "       'ImageBase', 'FileAlignment', 'MinorOperatingSystemVersion',\n",
      "       'MajorImageVersion', 'MinorSubsystemVersion', 'Subsystem',\n",
      "       'DllCharacteristics', 'SizeOfStackCommit', 'SizeOfHeapReserve',\n",
      "       'SizeOfHeapCommit', 'SectionMinEntropy', 'SectionMinRawsize',\n",
      "       'SectionMaxChar', 'DirectoryEntryImport', 'DirectoryEntryImportSize',\n",
      "       'DirectoryEntryExport'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "corrMatrix = X.corr()\n",
    "correlated_features = set()\n",
    "for i in range(len(corrMatrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corrMatrix.iloc[i, j]) > 0.8:\n",
    "            colname = corrMatrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "len(correlated_features)\n",
    "X.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "# print(corrMatrix)\n",
    "# f, ax = plt.subplots(figsize =(20, 18))\n",
    "# sns.heatmap(corrMatrix, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trainTest(X, y)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARACIÓNN DE ALGORITMOS MEDIANTE CROSS-VALIDATION\n",
      "LR: 0.999240 (0.001019)\n",
      "KNN9: 0.997721 (0.002654)\n",
      "KNN7: 0.998025 (0.002548)\n",
      "KNN5: 0.998481 (0.001359)\n",
      "KNN3: 0.998481 (0.001359)\n",
      "KNN1: 0.998937 (0.000973)\n",
      "RF: 0.999696 (0.000608)\n",
      "CART: 0.999696 (0.000608)\n",
      "NB: 0.998481 (0.001177)\n",
      "SVM: 0.997417 (0.001528)\n",
      "MLP: 0.999089 (0.001215)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   MLA used  Train Accuracy  Test Accuracy  Precision    Recall  F1-Score\n",
      "6        RF          1.0000         0.9988   1.000000  0.997599  0.998798\n",
      "7      CART          1.0000         0.9988   0.998800  0.998800  0.998800\n",
      "0        LR          0.9995         0.9982   0.998798  0.997599  0.998198\n",
      "5      KNN1          1.0000         0.9982   0.997602  0.998800  0.998200\n",
      "9       SVM          0.9995         0.9982   1.000000  0.996399  0.998196\n",
      "10      MLP          0.9995         0.9976   0.997599  0.997599  0.997599\n",
      "1      KNN9          0.9986         0.9970   0.996403  0.997599  0.997001\n",
      "2      KNN7          0.9985         0.9970   0.996403  0.997599  0.997001\n",
      "3      KNN5          0.9988         0.9970   0.996403  0.997599  0.997001\n",
      "4      KNN3          0.9989         0.9970   0.996403  0.997599  0.997001\n",
      "8        NB          0.9985         0.9964   0.997593  0.995198  0.996394\n"
     ]
    }
   ],
   "source": [
    "crossValidationScore(X_train, y_train)\n",
    "compareMLAs(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e6eaf00392b0cb8b5a646d3515e821c15d6342d64f11192f7e7dc8c1b273a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
