{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, auc, roc_curve, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import model_selection\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('KNN9', KNeighborsClassifier(n_neighbors=9)))\n",
    "models.append(('KNN7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('KNN5', KNeighborsClassifier()))\n",
    "models.append(('KNN3', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('KNN1', KNeighborsClassifier(n_neighbors=1)))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "\n",
    "features = []\n",
    "trained_models = []\n",
    "\n",
    "pd_b = pd.read_csv(\"./dataset_benign.csv\")\n",
    "pd_m = pd.read_csv(\"./dataset_malware.csv\")\n",
    "\n",
    "def getColumnsZeroStd():\n",
    "    global pd_b     # Variable global de dataset benigno\n",
    "    global pd_m     # Variable global de dataset maligno\n",
    "\n",
    "    benign = pd_b\n",
    "    malware = pd_m\n",
    "\n",
    "    pd.set_option('display.max_columns', 10)\n",
    "\n",
    "    drop = ['Name', 'Malware']\n",
    "    \n",
    "    b = benign.drop(['Name', 'Malware'], axis=1)\n",
    "    m = malware.drop(['Name', 'Malware'], axis=1)\n",
    "    for feature in b.columns:\n",
    "        # print(feature)\n",
    "        if b[feature].std() == 0:\n",
    "            drop.append(feature)\n",
    "    for feature in m.columns:\n",
    "        # print(feature)\n",
    "        if m[feature].std() == 0:\n",
    "            if feature not in drop:\n",
    "                drop.append(feature)\n",
    "\n",
    "    print(drop)\n",
    "    print(len(drop))\n",
    "\n",
    "    return drop\n",
    "\n",
    "def buildDataset(resample=\"\", drop=['Name', 'Malware']):\n",
    "    global pd_b\n",
    "    global pd_m\n",
    "\n",
    "    benign = pd_b\n",
    "    malware = pd_m\n",
    "\n",
    "    data = pd.concat([benign, malware], ignore_index=True)\n",
    "\n",
    "    X = data.drop(drop, axis=1)\n",
    "    y = data['Malware']\n",
    "\n",
    "\n",
    "    # print(names)\n",
    "\n",
    "    if (resample == \"-o\"):\n",
    "        print(\"Aplicando oversampling...\")\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "    elif (resample == \"-u\"):\n",
    "        print(\"\\n\\n\\nAplicando undersampling...\")\n",
    "        nearmiss = NearMiss(version=1)\n",
    "        X, y = nearmiss.fit_resample(X, y)\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(X)\n",
    "    print(\"Número de muestras totales:\", len(X), \"\\n\\n\\n\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def trainTest(X, y):\n",
    "    global features\n",
    "    features = X.columns\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "    sc = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    print(f'Número de características usadas: {X_train.shape[1]} \\n\\n\\n')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def crossValidationScore(X_train, y_train):\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'accuracy'\n",
    "    print(\"VALIDACIÓN CRUZADA\")\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5)\n",
    "        inicio = time.time()\n",
    "        trained_model = model.fit(X_train, y_train)\n",
    "        fin = time.time()\n",
    "        cv_results = model_selection.cross_val_score(\n",
    "            trained_model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f) (%fs)\" % (name, cv_results.mean(), cv_results.std(), (fin-inicio))\n",
    "        print(msg)\n",
    "        trained_models.append((name, trained_model))\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "def compareMLAs(X_train, X_test, y_train, y_test):\n",
    "    MLA_columns = []\n",
    "    MLA_compare = pd.DataFrame(columns=MLA_columns)\n",
    "\n",
    "    row_index = 0\n",
    "    for name, model in trained_models:\n",
    "\n",
    "        inicio = time.time()\n",
    "        predicted = model.predict(X_test)\n",
    "        fin=time.time()\n",
    "\n",
    "        tn, fp, fn, tp  = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "        MLA_name = name\n",
    "        MLA_compare.loc[row_index, 'MLA used'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'Train Accuracy'] = round(\n",
    "            model.score(X_train, y_train), 4)\n",
    "        MLA_compare.loc[row_index, 'Test Accuracy'] = round(\n",
    "            model.score(X_test, y_test), 4)\n",
    "        MLA_compare.loc[row_index, 'Precision'] = round(precision_score(\n",
    "            y_test, predicted), 4)\n",
    "        MLA_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),4)\n",
    "        MLA_compare.loc[row_index, 'F1-Score'] = round(f1_score(\n",
    "            y_test, predicted),4)\n",
    "        MLA_compare.loc[row_index, 'Tiempo de ejecución'] = (fin-inicio)\n",
    "        MLA_compare.loc[row_index, 'True negatives'] = tn\n",
    "        MLA_compare.loc[row_index, 'False positives'] = fp\n",
    "        MLA_compare.loc[row_index, 'False negatives'] = fn\n",
    "        MLA_compare.loc[row_index, 'True positives'] = tp\n",
    "\n",
    "        row_index += 1\n",
    "        \n",
    "    MLA_compare.sort_values(by=['Test Accuracy'],\n",
    "                            ascending=False, inplace=True)\n",
    "    display(MLA_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BENIGN\")\n",
    "display(pd_b.describe())\n",
    "print(\"MALWARE\")\n",
    "display(pd_m.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = getColumnsZeroStd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = buildDataset(\"-u\", drop)\n",
    "X_train, X_test, y_train, y_test = trainTest(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = X.corr()\n",
    "correlated_features = set()\n",
    "for i in range(len(corrMatrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corrMatrix.iloc[i, j]) > 0.8:\n",
    "            colname = corrMatrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "len(correlated_features)\n",
    "f, ax = plt.subplots(figsize =(13, 11))\n",
    "sns.heatmap(corrMatrix, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample=\"\" #\"-u\" -> aplicar undersampling    \"-o\" -> aplicar oversampling    \"\" -> no aplica ningun resampling\n",
    "\n",
    "X,y = buildDataset(resample, drop)\n",
    "X.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = trainTest(X, y)\n",
    "display(pd.DataFrame(features, columns=[\"Características\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationScore(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareMLAs(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e6eaf00392b0cb8b5a646d3515e821c15d6342d64f11192f7e7dc8c1b273a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
